#!/usr/bin/env python3
"""
Computer B - Memory Grid Experiment with Cross-Computer Gaze Display
Client version - displays Computer A's gaze as a red dot
Based on original memory grid code with networking functionality added
"""

import pylink
import os
import platform
import random
import time
import sys
import socket
import threading
import json
import numpy as np
from psychopy import visual, core, event, monitors, gui
from EyeLinkCoreGraphicsPsychoPy import EyeLinkCoreGraphicsPsychoPy
from PIL import Image
from string import ascii_letters, digits

# Global variables
el_tracker = None
win = None
client_socket = None

# Remote gaze display variables
remote_gaze_marker = None
remote_gaze_x = 0
remote_gaze_y = 0
gaze_data_lock = threading.Lock()
last_remote_gaze_update = 0

# Switch to the script folder
script_path = os.path.dirname(sys.argv[0])
if len(script_path) != 0:
    os.chdir(script_path)

# Show only critical log message in the PsychoPy console
from psychopy import logging
logging.console.setLevel(logging.CRITICAL)

# Configuration variables
use_retina = False
dummy_mode = False
full_screen = True

# Memory Grid Experiment Parameters
GRID_SIZE = 6
TOTAL_ROUNDS = 10
DISPLAY_TIME = 10.0
CATEGORIES = ['face', 'limbs', 'house', 'car']
IMAGES_PER_CATEGORY = 9

# Response keys for each category
RESPONSE_KEYS = {
    'f': 'face',
    'l': 'limbs', 
    'h': 'house',
    'c': 'car'
}

print("=" * 60)
print("COMPUTER B (CLIENT) - MEMORY GRID WITH CROSS-COMPUTER GAZE DISPLAY")
print("=" * 60)

def setup_client():
    """Set up client to connect to Computer A's server"""
    global client_socket
    
    try:
        print(f"Setting up client to connect to Computer A at 100.1.1.10:5555...")
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.settimeout(60.0)
        
        print("=" * 50)
        print("CONNECTING TO COMPUTER A...")
        print("Make sure Computer A is running and waiting for connection.")
        print("=" * 50)
        
        try:
            client_socket.connect(('100.1.1.10', 5555))
            client_socket.settimeout(None)
            print(f"✓ Connected to Computer A at 100.1.1.10:5555")
            return True
        except socket.timeout:
            print("Timeout connecting to Computer A")
            return False
        except ConnectionRefusedError:
            print("Connection refused - Computer A may not be running")
            return False
        
    except Exception as e:
        print(f"Client setup error: {e}")
        if client_socket:
            try:
                client_socket.close()
            except:
                pass
        return False

def receive_remote_gaze_data():
    """Receive Computer A's gaze data and update display"""
    global client_socket, remote_gaze_marker, win, remote_gaze_x, remote_gaze_y, gaze_data_lock, last_remote_gaze_update
    
    if client_socket is None:
        print("No connection for receiving gaze data")
        return
        
    data_buffer = ""
    print("Starting to receive Computer A's gaze data...")
    
    # Add a counter for debugging
    received_count = 0
    
    while True:
        try:
            data = client_socket.recv(1024).decode('utf-8')
            if not data:
                print("Computer A disconnected")
                break
                
            data_buffer += data
            
            if '\n' in data_buffer:
                lines = data_buffer.split('\n')
                
                for i in range(len(lines) - 1):
                    try:
                        gaze_json = json.loads(lines[i])
                        
                        if 'gaze_x' in gaze_json and 'gaze_y' in gaze_json:
                            raw_x = gaze_json['gaze_x']
                            raw_y = gaze_json['gaze_y']
                            
                            # Debug print every 100th update
                            received_count += 1
                            if received_count % 100 == 0:
                                print(f"DEBUG: Received {received_count} gaze updates. Latest: x={raw_x}, y={raw_y}")
                            
                            if win:
                                converted_x = raw_x - (win.size[0] / 2)
                                converted_y = (win.size[1] / 2) - raw_y
                                
                                with gaze_data_lock:
                                    remote_gaze_x = converted_x
                                    remote_gaze_y = converted_y
                                    last_remote_gaze_update = time.time()
                                
                                # Debug print first few conversions
                                if received_count <= 5:
                                    print(f"DEBUG: Converted coordinates: ({converted_x}, {converted_y})")
                                    
                    except (json.JSONDecodeError, KeyError) as e:
                        if received_count == 0:  # Only print first error
                            print(f"DEBUG: JSON decode error: {e}")
                        continue
                
                data_buffer = lines[-1]
                
        except Exception as e:
            print(f"Receive error: {e}")
            break

def send_our_gaze_data():
    """Send our gaze data to Computer A"""
    global client_socket, el_tracker
    
    if client_socket is None:
        print("No connection for sending gaze data")
        return
    
    print("Starting gaze data sender thread...")
    
    # Debug counter
    sent_count = 0
        
    while True:
        try:
            if el_tracker and el_tracker.isRecording():
                try:
                    sample = el_tracker.getNewestSample()
                    if sample is not None:
                        gaze_data = None
                        
                        if sample.isRightSample():
                            gaze_data = sample.getRightEye().getGaze()
                        elif sample.isLeftSample():
                            gaze_data = sample.getLeftEye().getGaze()
                            
                        if gaze_data and gaze_data[0] != pylink.MISSING_DATA and gaze_data[1] != pylink.MISSING_DATA:
                            data_to_send = json.dumps({"gaze_x": gaze_data[0], "gaze_y": gaze_data[1]})
                            client_socket.sendall((data_to_send + '\n').encode())
                            
                            # Debug print every 100th send
                            sent_count += 1
                            if sent_count % 100 == 0:
                                print(f"DEBUG: Sent {sent_count} gaze updates. Latest: x={gaze_data[0]}, y={gaze_data[1]}")
                                
                except Exception as sample_error:
                    pass
                        
            time.sleep(0.016)
        except Exception as e:
            print(f"Send error: {e}")
            break

def draw_remote_gaze_overlay():
    """Draw Computer A's gaze marker (red dot)"""
    global remote_gaze_marker, win, client_socket, gaze_data_lock, last_remote_gaze_update, remote_gaze_x, remote_gaze_y
    
    if remote_gaze_marker and win and client_socket:
        current_time = time.time()
        
        with gaze_data_lock:
            time_since_update = current_time - last_remote_gaze_update
            current_x = remote_gaze_x
            current_y = remote_gaze_y
        
        if time_since_update < 1.0:
            try:
                remote_gaze_marker.setPos([current_x, current_y])
                
                if time_since_update < 0.1:
                    remote_gaze_marker.setFillColor('red')
                    remote_gaze_marker.setOpacity(1.0)
                elif time_since_update < 0.5:
                    remote_gaze_marker.setFillColor('orange')
                    remote_gaze_marker.setOpacity(0.8)
                else:
                    remote_gaze_marker.setFillColor('gray')
                    remote_gaze_marker.setOpacity(0.5)
                
                remote_gaze_marker.draw()
            except Exception as e:
                pass

# Set up networking first
print("\n1. SETTING UP NETWORKING (CLIENT MODE)")
print("-" * 40)
connection_success = setup_client()

# Set up EDF data file name
edf_fname = 'COMP_B_CLIENT'

dlg_title = 'Computer B (Client) - Enter EDF File Name'
dlg_prompt = 'Please enter a file name with 8 or fewer characters\n[letters, numbers, and underscore].'

while True:
    dlg = gui.Dlg(dlg_title)
    dlg.addText(dlg_prompt)
    dlg.addField('File Name:', edf_fname)
    ok_data = dlg.show()
    if dlg.OK:
        print('EDF data filename: {}'.format(ok_data[0]))
    else:
        print('user cancelled')
        core.quit()
        sys.exit()

    tmp_str = dlg.data[0]
    edf_fname = tmp_str.rstrip().split('.')[0]

    allowed_char = ascii_letters + digits + '_'
    if not all([c in allowed_char for c in edf_fname]):
        print('ERROR: Invalid EDF filename')
    elif len(edf_fname) > 8:
        print('ERROR: EDF filename should not exceed 8 characters')
    else:
        break

# Set up folders
results_folder = 'results'
if not os.path.exists(results_folder):
    os.makedirs(results_folder)

time_str = time.strftime("_%Y_%m_%d_%H_%M", time.localtime())
session_identifier = edf_fname + time_str
session_folder = os.path.join(results_folder, session_identifier)
if not os.path.exists(session_folder):
    os.makedirs(session_folder)

# Connect to EyeLink
print("\n2. CONNECTING TO EYELINK")
print("-" * 30)
if dummy_mode:
    el_tracker = pylink.EyeLink(None)
    print("Running in DUMMY mode")
else:
    try:
        el_tracker = pylink.EyeLink("100.1.1.1")
        print("✓ Connected to EyeLink Host at 100.1.1.1")
        
        if el_tracker.isConnected():
            try:
                version = el_tracker.getTrackerVersionString()
                print(f"✓ Tracker version: {version}")
            except:
                print("⚠️  Could not get version string")
    except RuntimeError as error:
        print('ERROR:', error)
        print('Switching to dummy mode...')
        dummy_mode = True
        el_tracker = pylink.EyeLink(None)

# Open EDF file
edf_file = edf_fname + ".EDF"
try:
    el_tracker.openDataFile(edf_file)
    print(f"✓ Data file opened: {edf_file}")
except RuntimeError as err:
    print('ERROR:', err)
    if el_tracker.isConnected():
        el_tracker.close()
    core.quit()
    sys.exit()

# Configure tracker
print("\n3. CONFIGURING TRACKER")
print("-" * 25)
el_tracker.setOfflineMode()
pylink.msecDelay(100)

# Enhanced configuration for maximum data
commands = [
    "clear_screen 0",
    "sample_rate 1000",
    "link_sample_data = LEFT,RIGHT,GAZE,HREF,RAW,AREA,HTARGET,GAZERES,BUTTON,STATUS,INPUT",
    "link_event_filter = LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT",
    "file_sample_data = LEFT,RIGHT,GAZE,HREF,RAW,AREA,HTARGET,GAZERES,BUTTON,STATUS,INPUT", 
    "file_event_filter = LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT",
    "recording_parse_type = GAZE",
    "saccade_velocity_threshold = 30",
    "saccade_acceleration_threshold = 9500",
    "calibration_type = HV9"
]

for cmd in commands:
    el_tracker.sendCommand(cmd)
    pylink.msecDelay(10)

print("✓ Tracker configured for recording with real-time display")

# Set up LARGE graphics display
print("\n4. SETTING UP LARGE DISPLAY")
print("-" * 32)
mon = monitors.Monitor('myMonitor', width=53.0, distance=70.0)
win = visual.Window(fullscr=full_screen, monitor=mon, winType='pyglet', units='pix', color=[0, 0, 0])

scn_width, scn_height = win.size
print(f"✓ Large Window: {scn_width} x {scn_height}")

if 'Darwin' in platform.system() and use_retina:
    scn_width = int(scn_width/2.0)
    scn_height = int(scn_height/2.0)

# Configure EyeLink graphics
el_coords = "screen_pixel_coords = 0 0 %d %d" % (scn_width - 1, scn_height - 1)
el_tracker.sendCommand(el_coords)
print(f"✓ Screen coordinates: {el_coords}")

genv = EyeLinkCoreGraphicsPsychoPy(el_tracker, win)
foreground_color = (-1, -1, -1)
background_color = win.color
genv.setCalibrationColors(foreground_color, background_color)

# Set up calibration target
if os.path.exists('images/fixTarget.bmp'):
    genv.setTargetType('picture')
    genv.setPictureTarget(os.path.join('images', 'fixTarget.bmp'))

genv.setCalibrationSounds('', '', '')

if use_retina:
    genv.fixMacRetinaDisplay()

pylink.openGraphicsEx(genv)
print("✓ Graphics environment ready")

# Memory Grid Functions
def get_images_from_folders():
    """Load all images from category folders"""
    image_dict = {}
    
    for category in CATEGORIES:
        folder_path = category  # Assumes folders are in same directory as script
        if os.path.exists(folder_path):
            image_files = [f for f in os.listdir(folder_path) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
            image_dict[category] = [os.path.join(folder_path, img) for img in image_files]
        else:
            print(f"Warning: Folder '{category}' not found. Using placeholder.")
            image_dict[category] = [f"placeholder_{category}_{i}.png" for i in range(20)]
    
    return image_dict

def create_grid_positions(grid_size, image_size, spacing):
    """Create positions for a grid layout"""
    positions = []
    start_x = -(grid_size-1) * spacing / 2
    start_y = (grid_size-1) * spacing / 2
    
    for row in range(grid_size):
        for col in range(grid_size):
            x = start_x + col * spacing
            y = start_y - row * spacing
            positions.append((x, y))
    
    return positions

def select_images_for_round(image_dict):
    """Select and randomize images for one round"""
    selected_images = []
    image_categories = []
    
    # Select 9 images from each category
    for category in CATEGORIES:
        available_images = image_dict[category]
        if len(available_images) >= IMAGES_PER_CATEGORY:
            selected = random.sample(available_images, IMAGES_PER_CATEGORY)
        else:
            # If not enough images, repeat some
            selected = (available_images * ((IMAGES_PER_CATEGORY // len(available_images)) + 1))[:IMAGES_PER_CATEGORY]
        
        selected_images.extend(selected)
        image_categories.extend([category] * IMAGES_PER_CATEGORY)
    
    # Randomize the order
    combined = list(zip(selected_images, image_categories))
    random.shuffle(combined)
    selected_images, image_categories = zip(*combined)
    
    return list(selected_images), list(image_categories)

# Create visual elements
print("\n5. CREATING PRETTY VISUAL ELEMENTS")
print("-" * 35)

# Computer A's gaze marker (red) - no local gaze display
remote_gaze_marker = visual.Circle(win=win, radius=18, fillColor='red', lineColor='gold', lineWidth=4)
gaze_sparkle1 = visual.Circle(win=win, radius=8, fillColor='white', lineColor='lightcoral', lineWidth=2)
gaze_sparkle2 = visual.Circle(win=win, radius=4, fillColor='lightpink', lineColor='white', lineWidth=1)

# Cute corner decorations with pastel colors
corner_size = 35
corners = []
corner_sparkles = []
corner_positions = [
    (-scn_width//2 + corner_size, scn_height//2 - corner_size),  # Top-left
    (scn_width//2 - corner_size, scn_height//2 - corner_size),   # Top-right
    (-scn_width//2 + corner_size, -scn_height//2 + corner_size), # Bottom-left
    (scn_width//2 - corner_size, -scn_height//2 + corner_size)   # Bottom-right
]

pastel_colors = ['lightpink', 'lightblue', 'lightgreen', 'lightyellow']
for i, pos in enumerate(corner_positions):
    corner = visual.Circle(win=win, radius=20, fillColor=pastel_colors[i], lineColor='white', lineWidth=3, pos=pos)
    corners.append(corner)
    
    sparkle_pos = (pos[0] + 25, pos[1] - 25)
    sparkle = visual.Circle(win=win, radius=8, fillColor='white', lineColor='gold', 
                          lineWidth=2, pos=sparkle_pos)
    corner_sparkles.append(sparkle)

# Start networking threads if connected
if connection_success and client_socket:
    print("\n6. STARTING GAZE DATA EXCHANGE")
    print("-" * 32)
    
    # Start thread to receive Computer A's gaze data
    receive_thread = threading.Thread(target=receive_remote_gaze_data, daemon=True)
    receive_thread.start()
    print("✓ Started receiving Computer A's gaze data")
    
    # Start thread to send our gaze data to Computer A
    send_thread = threading.Thread(target=send_our_gaze_data, daemon=True)
    send_thread.start()
    print("✓ Started sending our gaze data to Computer A")
else:
    print("\n⚠️  WARNING: Not connected to Computer A - no gaze exchange")

# Instructions text
instruction_text = visual.TextStim(
    win, 
    text='Memory Grid Experiment\n\nComputer B (Client)\n\nPress SPACE to begin calibration\n\nRed dot = Computer A\'s gaze',
    color='white',
    height=30
)

# Main experiment preparation
print("\n7. STARTING EXPERIMENT")
print("-" * 25)

# Show instructions
instruction_text.draw()
# Draw decorative corners
for corner, sparkle in zip(corners, corner_sparkles):
    corner.draw()
    sparkle.draw()
win.flip()

# Wait for space key
event.waitKeys(keyList=['space'])

# Run calibration
try:
    el_tracker.doTrackerSetup()
except RuntimeError as err:
    print('ERROR:', err)
    el_tracker.exitCalibration()

# Load images
print("\nLoading images...")
image_dict = get_images_from_folders()

# Grid parameters
IMAGE_SIZE = 120
SPACING = 150
grid_positions = create_grid_positions(GRID_SIZE, IMAGE_SIZE, SPACING)

# Fixation cross
fixation = visual.ShapeStim(
    win,
    vertices=((0, -20), (0, 20), (0, 0), (-20, 0), (20, 0)),
    lineWidth=3,
    closeShape=False,
    lineColor='white'
)

# Results storage
results = []

# Main experiment loop
for round_num in range(TOTAL_ROUNDS):
    print(f"\nRound {round_num + 1}/{TOTAL_ROUNDS}")
    
    # Select images for this round
    selected_images, image_categories = select_images_for_round(image_dict)
    
    # Create image stimuli
    image_stims = []
    for i, (img_path, pos) in enumerate(zip(selected_images, grid_positions)):
        try:
            img = visual.ImageStim(win, image=img_path, pos=pos, size=(IMAGE_SIZE, IMAGE_SIZE))
            image_stims.append(img)
        except:
            # Fallback to text if image fails
            text = visual.TextStim(win, text=f"{image_categories[i]}\n{i+1}", 
                                 pos=pos, height=20, color='white')
            image_stims.append(text)
    
    # Show fixation
    el_tracker.sendMessage(f'ROUND_{round_num+1}_FIXATION')
    fixation.draw()
    draw_remote_gaze_overlay()  # Draw remote gaze during fixation
    win.flip()
    core.wait(1.0)
    
    # Start recording
    el_tracker.startRecording(1, 1, 1, 1)
    pylink.msecDelay(100)
    
    # Display grid
    el_tracker.sendMessage(f'ROUND_{round_num+1}_GRID_ON')
    display_start = core.getTime()
    
    while core.getTime() - display_start < DISPLAY_TIME:
        # Draw all images
        for img in image_stims:
            img.draw()
        
        # Draw remote gaze overlay
        draw_remote_gaze_overlay()
        
        # Check for escape key
        keys = event.getKeys(['escape'])
        if 'escape' in keys:
            el_tracker.stopRecording()
            break
        
        win.flip()
    
    # Stop recording
    el_tracker.stopRecording()
    
    # Clear screen
    el_tracker.sendMessage(f'ROUND_{round_num+1}_GRID_OFF')
    win.flip()
    core.wait(0.5)
    
    # Response phase
    response_text = visual.TextStim(
        win,
        text='Which category was in position X?\n\nF=Face  L=Limbs  H=House  C=Car\n\nPress key to respond',
        height=25,
        color='white'
    )
    
    # Test random positions
    test_positions = random.sample(range(len(grid_positions)), 5)
    
    for test_idx, grid_idx in enumerate(test_positions):
        # Update response text
        response_text.text = f'Which category was in position {grid_idx+1}?\n\nF=Face  L=Limbs  H=House  C=Car'
        
        # Show response prompt
        response_text.draw()
        draw_remote_gaze_overlay()  # Draw remote gaze during response
        win.flip()
        
        # Wait for response
        response_start = core.getTime()
        keys = event.waitKeys(keyList=['f', 'l', 'h', 'c', 'escape'])
        response_time = core.getTime() - response_start
        
        if 'escape' in keys:
            break
        
        # Record result
        response_category = RESPONSE_KEYS[keys[0]]
        correct_category = image_categories[grid_idx]
        is_correct = response_category == correct_category
        
        result = {
            'round': round_num + 1,
            'test_position': grid_idx + 1,
            'correct_category': correct_category,
            'response_category': response_category,
            'correct': is_correct,
            'response_time': response_time
        }
        results.append(result)
        
        # Brief feedback
        feedback_text = 'Correct!' if is_correct else f'Incorrect (was {correct_category})'
        feedback = visual.TextStim(win, text=feedback_text, height=30, 
                                 color='green' if is_correct else 'red')
        feedback.draw()
        draw_remote_gaze_overlay()  # Draw remote gaze during feedback
        win.flip()
        core.wait(0.5)
    
    # Inter-round interval
    if round_num < TOTAL_ROUNDS - 1:
        break_text = visual.TextStim(win, text=f'Round {round_num+1} complete\n\nPress SPACE to continue', 
                                    height=25, color='white')
        break_text.draw()
        draw_remote_gaze_overlay()  # Draw remote gaze during break
        win.flip()
        event.waitKeys(keyList=['space'])

# End of experiment
el_tracker.sendMessage('EXPERIMENT_END')

# Calculate and show results
correct_count = sum(1 for r in results if r['correct'])
total_trials = len(results)
accuracy = (correct_count / total_trials * 100) if total_trials > 0 else 0

end_text = visual.TextStim(
    win,
    text=f'Experiment Complete!\n\nAccuracy: {accuracy:.1f}%\n({correct_count}/{total_trials} correct)\n\nPress SPACE to exit',
    height=30,
    color='white'
)

end_text.draw()
draw_remote_gaze_overlay()  # Draw remote gaze at end
win.flip()
event.waitKeys(keyList=['space'])

# Terminate task function
def terminate_task():
    """Clean up and exit the experiment"""
    global el_tracker, client_socket
    
    print("\n8. CLEANING UP")
    print("-" * 20)
    
    # Close socket
    if client_socket:
        try:
            client_socket.close()
            print("✓ Network connection closed")
        except:
            pass
    
    # Handle EyeLink cleanup
    if el_tracker and el_tracker.isConnected():
        try:
            if el_tracker.isRecording():
                el_tracker.stopRecording()
            el_tracker.setOfflineMode()
            el_tracker.sendCommand('clear_screen 0')
            pylink.msecDelay(500)
            el_tracker.closeDataFile()
            
            # Download EDF file
            local_edf = os.path.join(session_folder, edf_file)
            try:
                el_tracker.receiveDataFile(edf_file, local_edf)
                print(f"✓ EDF file saved: {local_edf}")
            except RuntimeError as error:
                print(f'ERROR downloading EDF: {error}')
            
            el_tracker.close()
        except Exception as e:
            print(f"Cleanup error: {e}")
    
    # Save behavioral results
    import csv
    results_file = os.path.join(session_folder, 'behavioral_results.csv')
    with open(results_file, 'w', newline='') as f:
        if results:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
    print(f"✓ Results saved: {results_file}")
    
    # Close window
    win.close()
    core.quit()
    
    print("\n✓ Experiment complete!")
    print("=" * 40)
    sys.exit()

# Call terminate_task at the end
terminate_task()
