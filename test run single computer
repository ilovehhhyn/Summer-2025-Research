#!/usr/bin/env python3
"""
Single Computer Eye Tracking with Real-time Gaze Display
Based on the original Computer A code but modified to show your own gaze as a dot
No networking - just local eye tracking with gaze visualization
"""

from __future__ import division
from __future__ import print_function

import pylink
import os
import platform
import random
import time
import sys
from EyeLinkCoreGraphicsPsychoPy import EyeLinkCoreGraphicsPsychoPy
from psychopy import visual, core, event, monitors, gui
from PIL import Image
from string import ascii_letters, digits

# Global variables
el_tracker = None
win = None
gaze_marker = None

# Switch to the script folder
script_path = os.path.dirname(sys.argv[0])
if len(script_path) != 0:
    os.chdir(script_path)

# Show only critical log message in the PsychoPy console
from psychopy import logging
logging.console.setLevel(logging.CRITICAL)

# Configuration variables
use_retina = False
dummy_mode = False  # Set to True if you don't have an actual eye tracker
full_screen = True

# Set up EDF data file name
edf_fname = 'GAZE_TEST'

# Prompt user to specify an EDF data filename
dlg_title = 'Eye Tracking with Gaze Display - Enter EDF File Name'
dlg_prompt = 'Please enter a file name with 8 or fewer characters\n[letters, numbers, and underscore].'

while True:
    dlg = gui.Dlg(dlg_title)
    dlg.addText(dlg_prompt)
    dlg.addField('File Name:', edf_fname)
    ok_data = dlg.show()
    if dlg.OK:
        print('EDF data filename: {}'.format(ok_data[0]))
    else:
        print('user cancelled')
        core.quit()
        sys.exit()

    tmp_str = dlg.data[0]
    edf_fname = tmp_str.rstrip().split('.')[0]

    allowed_char = ascii_letters + digits + '_'
    if not all([c in allowed_char for c in edf_fname]):
        print('ERROR: Invalid EDF filename')
    elif len(edf_fname) > 8:
        print('ERROR: EDF filename should not exceed 8 characters')
    else:
        break

# Set up folders
results_folder = 'results'
if not os.path.exists(results_folder):
    os.makedirs(results_folder)

time_str = time.strftime("_%Y_%m_%d_%H_%M", time.localtime())
session_identifier = edf_fname + time_str
session_folder = os.path.join(results_folder, session_identifier)
if not os.path.exists(session_folder):
    os.makedirs(session_folder)

# Connect to EyeLink
if dummy_mode:
    el_tracker = pylink.EyeLink(None)
else:
    try:
        el_tracker = pylink.EyeLink("100.1.1.1")
    except RuntimeError as error:
        print('ERROR:', error)
        print('Switching to dummy mode...')
        dummy_mode = True
        el_tracker = pylink.EyeLink(None)

# Open EDF file
edf_file = edf_fname + ".EDF"
try:
    el_tracker.openDataFile(edf_file)
except RuntimeError as err:
    print('ERROR:', err)
    if el_tracker.isConnected():
        el_tracker.close()
    core.quit()
    sys.exit()

# Configure tracker
el_tracker.setOfflineMode()

# Get tracker version
eyelink_ver = 0
if not dummy_mode:
    vstr = el_tracker.getTrackerVersionString()
    eyelink_ver = int(vstr.split()[-1].split('.')[0])
    print('Running experiment on %s, version %d' % (vstr, eyelink_ver))

# Set up tracking parameters
file_event_flags = 'LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT'
link_event_flags = 'LEFT,RIGHT,FIXATION,SACCADE,BLINK,BUTTON,FIXUPDATE,INPUT'

if eyelink_ver > 3:
    file_sample_flags = 'LEFT,RIGHT,GAZE,HREF,RAW,AREA,HTARGET,GAZERES,BUTTON,STATUS,INPUT'
    link_sample_flags = 'LEFT,RIGHT,GAZE,GAZERES,AREA,HTARGET,STATUS,INPUT'
else:
    file_sample_flags = 'LEFT,RIGHT,GAZE,HREF,RAW,AREA,GAZERES,BUTTON,STATUS,INPUT'
    link_sample_flags = 'LEFT,RIGHT,GAZE,GAZERES,AREA,STATUS,INPUT'

el_tracker.sendCommand("file_event_filter = %s" % file_event_flags)
el_tracker.sendCommand("file_sample_data = %s" % file_sample_flags)
el_tracker.sendCommand("link_event_filter = %s" % link_event_flags)
el_tracker.sendCommand("link_sample_data = %s" % link_sample_flags)
el_tracker.sendCommand("calibration_type = HV9")

# Set up graphics
mon = monitors.Monitor('myMonitor', width=53.0, distance=70.0)
win = visual.Window(fullscr=full_screen, monitor=mon, winType='pyglet', units='pix')

scn_width, scn_height = win.size
if 'Darwin' in platform.system() and use_retina:
    scn_width = int(scn_width/2.0)
    scn_height = int(scn_height/2.0)

# Configure EyeLink graphics
el_coords = "screen_pixel_coords = 0 0 %d %d" % (scn_width - 1, scn_height - 1)
el_tracker.sendCommand(el_coords)

genv = EyeLinkCoreGraphicsPsychoPy(el_tracker, win)
foreground_color = (-1, -1, -1)
background_color = win.color
genv.setCalibrationColors(foreground_color, background_color)

# Set up calibration target
if os.path.exists('images/fixTarget.bmp'):
    genv.setTargetType('picture')
    genv.setPictureTarget(os.path.join('images', 'fixTarget.bmp'))

genv.setCalibrationSounds('', '', '')

if use_retina:
    genv.fixMacRetinaDisplay()

pylink.openGraphicsEx(genv)

# Create gaze marker for showing your own gaze position
gaze_marker = visual.Circle(win=win, radius=8, fillColor='red', lineColor='white', lineWidth=2, pos=[0, 0])

# Function to get current gaze position and update marker
def update_gaze_marker():
    """Get current gaze position from eye tracker and update marker position"""
    global el_tracker, gaze_marker, win
    
    if el_tracker and el_tracker.isRecording():
        sample = el_tracker.getNewestSample()
        if sample is not None:
            # Try to get gaze data from right eye first, then left eye
            if sample.isRightSample():
                gaze_data = sample.getRightEye().getGaze()
            elif sample.isLeftSample():
                gaze_data = sample.getLeftEye().getGaze()
            else:
                return  # No valid sample
                
            # Check if gaze data is valid (not missing)
            if gaze_data and gaze_data[0] != pylink.MISSING_DATA and gaze_data[1] != pylink.MISSING_DATA:
                # Convert from EyeLink coordinates to PsychoPy coordinates
                # EyeLink: (0,0) at top-left, PsychoPy: (0,0) at center
                gaze_x = gaze_data[0] - win.size[0]/2
                gaze_y = win.size[1]/2 - gaze_data[1]
                
                # Update marker position
                gaze_marker.setPos([gaze_x, gaze_y])
                
                # Optional: Change color based on which eye is being tracked
                if sample.isRightSample():
                    gaze_marker.setFillColor('red')
                else:
                    gaze_marker.setFillColor('blue')

# Helper functions (keeping original structure)
def clear_screen(win):
    win.fillColor = genv.getBackgroundColor()
    win.flip()

def show_msg(win, text, wait_for_keypress=True):
    msg = visual.TextStim(win, text, color=genv.getForegroundColor(), wrapWidth=scn_width/2)
    clear_screen(win)
    msg.draw()
    win.flip()
    if wait_for_keypress:
        event.waitKeys()
        clear_screen(win)

def terminate_task():
    global el_tracker
    
    if el_tracker and el_tracker.isConnected():
        if el_tracker.isRecording():
            el_tracker.stopRecording()
        el_tracker.setOfflineMode()
        el_tracker.sendCommand('clear_screen 0')
        pylink.msecDelay(500)
        el_tracker.closeDataFile()
        
        # Download EDF file
        local_edf = os.path.join(session_folder, session_identifier + '.EDF')
        try:
            el_tracker.receiveDataFile(edf_file, local_edf)
        except RuntimeError as error:
            print('ERROR:', error)
        
        el_tracker.close()
    
    win.close()
    core.quit()
    sys.exit()

# Show instructions
task_msg = 'Eye Tracking with Real-time Gaze Display\n\n'
task_msg += 'You will see a red/blue dot showing where you are looking\n\n'
task_msg += 'Press Ctrl-C to quit the task early\n'
if dummy_mode:
    task_msg += '\nDUMMY MODE: No real eye tracking\n'
    task_msg += 'Press ENTER to start the task'
else:
    task_msg += '\nPress ENTER twice to calibrate tracker'

show_msg(win, task_msg)

# Calibration
if not dummy_mode:
    try:
        el_tracker.doTrackerSetup()
    except RuntimeError as err:
        print('ERROR:', err)
        el_tracker.exitCalibration()

# Main experiment (keeping original structure but adding gaze display)
try:
    # Define stimuli paths (keeping original)
    if not os.path.exists("PSY stimuli"):
        os.makedirs("PSY stimuli")
    
    # For demo purposes, create simple text stimuli if images don't exist
    images = []
    image_names = ["car.png", "hand.png", "face.png", "house.png"]
    for name in image_names:
        if os.path.exists(f"PSY stimuli/{name}"):
            images.append(f"PSY stimuli/{name}")
        else:
            images.append(None)  # Will use text instead
    
    # Grid positions (keeping original)
    grid_positions = [(-200, 200), (200, 200), (-200, -200), (200, -200)]
    image_size = (150, 150)
    
    # Start recording
    el_tracker.startRecording(1, 1, 1, 1)
    
    # Main trial loop (keeping original structure)
    num_trials = 4
    for trial in range(num_trials):
        print(f"Starting trial {trial + 1}")
        
        el_tracker.sendMessage(f'TRIALID {trial}')
        
        # Show fixation with real-time gaze marker
        fixation = visual.TextStim(win, text="+", color=(-1, -1, -1), height=50)
        
        # Fixation period with real-time gaze updates
        start_time = core.getTime()
        while core.getTime() - start_time < 1.0:
            fixation.draw()
            
            # Update and draw gaze marker
            update_gaze_marker()
            gaze_marker.draw()
            
            win.flip()
            core.wait(0.016)  # ~60Hz refresh rate
            
            # Check for quit
            keys = event.getKeys()
            if 'escape' in keys:
                raise KeyboardInterrupt
        
        # Show stimuli with real-time gaze marker
        shuffled_positions = random.sample(grid_positions, len(grid_positions))
        
        el_tracker.sendMessage('stimuli_onset')
        
        # Stimulus presentation period with real-time gaze updates
        start_time = core.getTime()
        while core.getTime() - start_time < 3.0:
            # Draw stimuli
            for i, pos in enumerate(shuffled_positions):
                if images[i] and os.path.exists(images[i]):
                    stim = visual.ImageStim(win, image=images[i], pos=pos, size=image_size)
                else:
                    # Use text if image doesn't exist
                    text_labels = ["CAR", "HAND", "FACE", "HOUSE"]
                    stim = visual.TextStim(win, text=text_labels[i], pos=pos, color=(-1, -1, -1), height=30)
                stim.draw()
            
            # Update and draw gaze marker
            update_gaze_marker()
            gaze_marker.draw()
            
            win.flip()
            core.wait(0.016)  # ~60Hz refresh rate
            
            # Check for quit
            keys = event.getKeys()
            if 'escape' in keys:
                raise KeyboardInterrupt
        
        # Clear screen
        clear_screen(win)
        el_tracker.sendMessage('stimuli_offset')
        core.wait(1.0)
        
        # Check for quit
        keys = event.getKeys()
        if 'escape' in keys:
            break
    
    # Stop recording
    el_tracker.stopRecording()
    
except KeyboardInterrupt:
    print("Experiment interrupted by user")
except Exception as e:
    print(f"Experiment error: {e}")

finally:
    terminate_task()
